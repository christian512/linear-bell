{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Find Bell inequalities using linear programming\n",
    "\n",
    "This notebooks demonstrates the locality test for a behavior $p$. We restrict the dimensions to two outputs $\\Delta = 2$\n",
    "and two inputs $m = 2$ at each of the two parties.\n",
    "\n",
    "### Local example\n",
    "First we will consider a local example. We take a probability distribution that is totally independent of the inputs, i.e.\n",
    "all possible outcomes have the same probability $p(ab|xy) = \\frac{1}{4}$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "# define inputs and outputs\n",
    "inputs = [0,1]\n",
    "outputs = [-1,1]\n",
    "dim = (len(outputs)**2) * (len(inputs)**2)\n",
    "\n",
    "# define probabilities\n",
    "def prob(a,b,x,y):\n",
    "    return 1/4\n",
    "\n",
    "# define behavior\n",
    "p = []\n",
    "for x,y in itertools.product(inputs,inputs):\n",
    "    for a,b in itertools.product(outputs,outputs):\n",
    "        p.append(prob(a,b,x,y))\n",
    "p = np.array(p)\n",
    "assert len(p) == dim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have now defined the behavior as a vector in $\\mathbb{R}^{\\Delta^2 \\cdot m^2}$. Now we have to define the deterministic\n",
    "behaviors, which are defined as:\n",
    "\n",
    "$$ d_\\lambda(ab|xy) = 1 \\quad \\text{if } a=a_x \\text{ and } b=b_y \\quad\\text{; otherwise } 0$$\n",
    "\n",
    "Hence we create a list of all possible local hidden variables (there are $\\Delta^{2m}$) possibilities. For\n",
    "each hidden variable, we iterate over the possible input/output combinations and set the entries to one, where the outputs\n",
    "match to the ones predicted by the hidden variable. This looks a bit complex and there might be a better way to do it.\n",
    "Tell me if you know it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# create a list of all hidden variables\n",
    "lhvs = itertools.product(outputs, repeat=2*len(inputs))\n",
    "# list of all deterministic behaviors\n",
    "deterministics = []\n",
    "for lhv in lhvs:\n",
    "    d = np.zeros(dim)\n",
    "    counter = 0\n",
    "    # iterate over the possible input and output combinations\n",
    "    for x,y in itertools.product(inputs,inputs):\n",
    "        for a,b in itertools.product(outputs,outputs):\n",
    "            # check if the actual output is matching to the LHV output -> set entry in d_lambda to one if true\n",
    "            if lhv[x] == a and lhv[y+len(inputs)] == b:\n",
    "                d[counter] = 1.0\n",
    "            counter += 1\n",
    "    deterministics.append(d)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dual form of the linear problem had the following form:\n",
    "\n",
    "$$\\text{maximize } S = s\\cdot p - S_l \\text{ such that}$$ <br>\n",
    "$$ s \\cdot d_\\lambda - S_l \\leq 0 \\quad \\forall \\lambda = 1,..., \\Delta^{2m} $$ <br>\n",
    "$$ s \\cdot p - S_l \\leq 1 $$\n",
    "\n",
    "However the *SciPy* solver only allows a dot product as the objective function. We therefore define an *extended behavior*\n",
    "and *extended deterministic behaviors*, which are the usual behaviors with a $-1$ appended as last entry:\n",
    "\n",
    "$$ \\tilde{p} = (p, -1) \\quad \\text{and} \\quad \\tilde{d_\\lambda} = (d_\\lambda, -1) $$\n",
    "\n",
    "Additionally the *SciPy* solver can only solve minimization problem. Thus we rewrite the problem as the following:\n",
    "\n",
    "$$\\text{minimize } -S = -\\tilde{s}\\cdot \\tilde{p} \\text{ such that}$$ <br>\n",
    "$$ \\tilde{s} \\cdot \\tilde{d_\\lambda}  \\leq 0 \\quad \\forall \\lambda = 1,..., \\Delta^{2m} $$ <br>\n",
    "$$ \\tilde{s} \\cdot \\tilde{p} \\leq 1 $$\n",
    "\n",
    "where $\\tilde{s} = (s, S_l)$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "#update the behavior\n",
    "p = np.append(p, [-1.0])\n",
    "# update the deterministic behaviors\n",
    "for i in range(dim):\n",
    "    deterministics[i] = np.append(deterministics[i],[-1.0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The objective function and the inequalities need to be expressed in a specific  form, that the solver can handle them.\n",
    "For more details you can look in the documentation of *SciPy*."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n"
     ]
    }
   ],
   "source": [
    "# objective function\n",
    "obj = -p\n",
    "# left hand side of inequalities\n",
    "lhs_ineq = np.copy(deterministics)\n",
    "lhs_ineq = np.append(lhs_ineq, [p], axis=0)\n",
    "\n",
    "\n",
    "# right hand side of the inequalities\n",
    "rhs_ineq = np.zeros(dim+1)\n",
    "rhs_ineq[-1] = 1.0\n",
    "\n",
    "# run the optimizer\n",
    "from scipy.optimize import linprog\n",
    "opt = linprog(c=obj, A_ub=lhs_ineq, b_ub=rhs_ineq)\n",
    "print(opt.message)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can obtain the optimal values from the result of the optimizer. If the behavior is local it should fulfill the\n",
    "inequality:\n",
    "\n",
    "$$ S = s \\cdot p - S_l \\leq 0$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S = 1.3259798814502233e-10\n",
      "CHSH = 0.0\n"
     ]
    }
   ],
   "source": [
    "S = np.dot(p,opt.x)\n",
    "print('S = {}'.format(S))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, the inequality $S = s \\cdot p - S_l \\leq 0$ is fulfilled (up to numerical uncertainty).\n",
    "Thus the behavior we have tested is local, i.e. $p \\in \\mathcal{L}$.\n",
    "\n",
    "# Non local behavior\n",
    "Before we have used a local behavior, to show that the linear program gives the right solution for such a behavior.\n",
    "Now we will redefine the behavior to be a non-local one. Therefore we will use the famous example of PR-box."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# probability for PR box\n",
    "def prob(a,b,x,y):\n",
    "    s = x*y\n",
    "    if a == -1: a=0\n",
    "    if b == -1: b=0\n",
    "    t = (a+b) % 2\n",
    "    return 1/2 * int(s==t)\n",
    "# redefine the local behavior\n",
    "p = []\n",
    "for x,y in itertools.product(inputs,inputs):\n",
    "    for a,b in itertools.product(outputs,outputs):\n",
    "        p.append(prob(a,b,x,y))\n",
    "p = np.array(p)\n",
    "p = np.append(p, [-1.0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ready to run the optimization."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "S = 0.9999999992615258\n",
      "CHSH = 4.0\n"
     ]
    }
   ],
   "source": [
    "# objective function\n",
    "obj = -p\n",
    "# left hand side of inequalities\n",
    "lhs_ineq = np.copy(deterministics)\n",
    "lhs_ineq = np.append(lhs_ineq, [p], axis=0)\n",
    "\n",
    "# right hand side of the inequalities\n",
    "rhs_ineq = np.zeros(dim+1)\n",
    "rhs_ineq[-1] = 1.0\n",
    "\n",
    "# run the optimizer\n",
    "opt = linprog(c=obj, A_ub=lhs_ineq, b_ub=rhs_ineq)\n",
    "print(opt.message)\n",
    "\n",
    "print('S = {}'.format(np.dot(opt.x,p)))\n",
    "\n",
    "# check the CHSH inequality\n",
    "chsh = 0\n",
    "for a,b in itertools.product(outputs,outputs):\n",
    "    chsh += a*b*prob(a,b,0,0)\n",
    "    chsh += a*b*prob(a,b,0,1)\n",
    "    chsh += a*b*prob(a,b,1,0)\n",
    "    chsh -= a*b*prob(a,b,1,1)\n",
    "print('CHSH = {}'.format(chsh))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}