{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Enumerate Facet inequalities for a given number of inputs and binary outputs\n",
    "Here I want to implement an algorithm, to find all facet inequalities for a given number of inputs and binary outputs.\n",
    "This follows the construction of *Algorithm 1* in the paper [*Bell inequalities from no-signalling distribution*, *Cope & Colbeck (2019)*](https://arxiv.org/abs/1812.10017).\n",
    "\n",
    "First we set the number of inputs and outputs and obtain the extremal points for the specific NS polytope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from utils import extremal_ns_binary_vertices, get_deterministic_behaviors, get_allowed_relabellings\n",
    "import numpy as np\n",
    "# set inputs / outputs\n",
    "inputs_a = range(3)\n",
    "inputs_b = range(3)\n",
    "outputs = range(2)\n",
    "epsilons = np.linspace(1/3,2/3, num=3)\n",
    "file = 'facets/3322_3eps.txt'\n",
    "# get extremal points\n",
    "extremals = extremal_ns_binary_vertices(inputs_a, inputs_b, outputs)\n",
    "\n",
    "# get deterministic points\n",
    "dets = get_deterministic_behaviors(inputs_a, inputs_b, outputs)\n",
    "\n",
    "# get allowed relabellings\n",
    "allowed_relabellings = get_allowed_relabellings(inputs_a, inputs_b, outputs, outputs)\n",
    "\n",
    "# options for local weight optimizer (bland is only needed for higher dimensions (m_a , m_b > 4)\n",
    "options = {\"disp\": False, \"maxiter\": 5000, \"bland\": True}\n",
    "\n",
    "method='simplex'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 8 : num of facets: 0\n",
      "num facets: 1\n",
      "1 / 8 : num of facets: 1\n",
      "num facets: 2\n",
      "2 / 8 : num of facets: 2\n",
      "3 / 8 : num of facets: 2\n",
      "4 / 8 : num of facets: 2\n",
      "5 / 8 : num of facets: 2\n",
      "6 / 8 : num of facets: 2\n",
      "7 / 8 : num of facets: 2\n",
      "Number of facet classes found: 2\n"
     ]
    }
   ],
   "source": [
    "from utils import find_local_weight, facet_inequality_check, check_equiv_relabel_repr\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# list of all facets\n",
    "facets = []\n",
    "# iterate through extremals\n",
    "# TODO: Update algorithm as it continues and does not go to epsilon part if first inequality is not a facet\n",
    "for z, e in enumerate(extremals):\n",
    "    print('{} / {} : num of facets: {}'.format(z,len(extremals),len(facets)))\n",
    "    # find the local weight for the extremal behavior\n",
    "    opt, bell_expression = find_local_weight(e, dets, method=method, options=options)\n",
    "\n",
    "    # check that there is no local part, as it is an extremal point\n",
    "    assert np.abs(bell_expression @ e) < 1e-6, 'local weight of extremal is not zero: {}'.format(np.abs(bell_expression @ e))\n",
    "    # find all equalizing local behaviors for the inequality bell_expression @ d >= 1\n",
    "    is_facet, bell_expression, eq_dets = facet_inequality_check(dets, bell_expression, len(inputs_a), len(inputs_b), len(outputs))\n",
    "    # check if other representation is already in facets\n",
    "    if is_facet:\n",
    "        check = [check_equiv_relabel_repr(bell_expression,f,allowed_relabellings,dets) for f in facets]\n",
    "        if True in check: is_facet = False\n",
    "    if is_facet:\n",
    "        facets.append(bell_expression)\n",
    "        print('num facets: {}'.format(len(facets)))\n",
    "    # iterate through epsilons\n",
    "    for epsilon in epsilons:\n",
    "        # define new behaviors based on epsilon\n",
    "        for j,k in product(range(eq_dets.shape[0]),repeat=2):\n",
    "            # need distinct j,k\n",
    "            if j == k:\n",
    "                continue\n",
    "            # form new probability distribution\n",
    "            e_new = (1-3*epsilon/2)*e + epsilon*eq_dets[j] + epsilon / 2 * eq_dets[k]\n",
    "            # do the facet check again\n",
    "            opt, bell_expression = find_local_weight(e_new, dets,method=method, options=options)\n",
    "\n",
    "            is_facet, bell_expression, eq_dets_new = facet_inequality_check(dets, bell_expression, len(inputs_a), len(inputs_b), len(outputs))\n",
    "            # do the same checks as above, could be done in a better way\n",
    "            if not is_facet: continue\n",
    "            check = [check_equiv_relabel_repr(bell_expression,f,allowed_relabellings,dets) for f in facets]\n",
    "            if True in check: continue\n",
    "            facets.append(bell_expression)\n",
    "            print('num facets: {}'.format(len(facets)))\n",
    "print('Number of facet classes found: {}'.format(len(facets)))\n",
    "facets = np.array(facets)\n",
    "np.savetxt(file, facets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have found the number of classes of facets for a specific number of inputs and outputs.\n",
    "Howeer we did not yet start relabel the outputs. Thus we find too many facet inequalities. E.g. in the case of\n",
    "3,3,2,2 where there should be only 2 facets but we find more than that..\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}